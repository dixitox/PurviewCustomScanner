{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CODE CELL 1 ==========\n",
    "# Reload the purview_utils module to pick up changes\n",
    "import importlib\n",
    "import custom_libs.purview_utils\n",
    "import custom_libs.sharepoint_utils\n",
    "importlib.reload(custom_libs.purview_utils)\n",
    "importlib.reload(custom_libs.sharepoint_utils)\n",
    "from custom_libs.purview_utils import loadPurviewAssets, applyPurviewClassifications\n",
    "from custom_libs.sharepoint_utils import SharePointUtils\n",
    "\n",
    "# Recreate SharePoint client with updated code\n",
    "sharepointClient = SharePointUtils()\n",
    "sharepointClient.loadEnvFile()\n",
    "response = sharepointClient.msgraph_auth()\n",
    "\n",
    "print(\"‚úÖ Reloaded purview_utils and sharepoint_utils modules\")\n",
    "print(\"‚úÖ Recreated SharePoint client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Getting Started\n",
    "\n",
    "üí°<b> Before running this notebook</b>, ensure you have configured SharePoint, Azure AI Foundry, set up an application for handling API authentication, granted appropriate roles in Microsoft Purview, and set the appropriate configuration parameters. [Steps listed here.](README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CODE CELL 5 ==========\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CODE CELL 7 ==========\n",
    "import os\n",
    "# The JSON module could be potentially removed\n",
    "import json\n",
    "from azure.identity import ClientSecretCredential\n",
    "from pyapacheatlas.core import PurviewClient\n",
    "from purviewautomation import PurviewCollections, ServicePrincipalAuthentication\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from pyapacheatlas.core.typedef import ClassificationTypeDef, EntityTypeDef\n",
    "# Purview custom libraries\n",
    "from custom_libs.purview_utils import (\n",
    "    filesystemFileSampleList,\n",
    "    listFilesystemFiles,\n",
    "    getAADToken,\n",
    "    moveCollection,\n",
    "    estimateTokens,\n",
    "    unstructuredDataClassification,\n",
    "    rollupClassifications,\n",
    "    loadPurviewAssets,\n",
    "    applyPurviewClassifications\n",
    ")\n",
    "# SharePoint custom libraries\n",
    "from custom_libs.sharepoint_utils import (\n",
    "    SharePointUtils,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Initialize Environment\n",
    "\n",
    "Before running this notebook, you must configure certain environment variables. We will now use environment variables to store our configuration. This is a more secure practice as it prevents sensitive data from being accidentally committed and pushed to version control systems.\n",
    "\n",
    "Create a `.env` file in your project root (use the provided `.env.sample` as a template). [Detailed steps here](README.md)\n",
    "\n",
    "> üìå **Note**\n",
    "> Remember not to commit the .env file to your version control system. Add it to your .gitignore file to prevent it from being tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CODE CELL 9 ==========\n",
    "# Instantiate the SharePointDataExtractor client\n",
    "# The client handles the complexities of interacting with SharePoint's REST API, providing an easy-to-use interface for data extraction.\n",
    "sharepointClient = SharePointUtils()\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "sharepointClient.loadEnvFile()\n",
    "\n",
    "# Retrieve environment variables\n",
    "azureOpenAIApiKey=os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
    "azureOpenAIDeploymentName=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "azureOpenAILLMModel=os.getenv(\"AZURE_OPENAI_LLM_MODEL\")\n",
    "azureOpenAIApiEndpoint= os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azureOpenAIApiVersion= os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "purviewAccountName = os.getenv(\"PURVIEW_ACCOUNT_NAME\")\n",
    "purviewEndpointUrl=os.getenv(\"PURVIEW_ENDPOINT_URL\")\n",
    "purviewTokenUrl=os.getenv(\"PURVIEW_TOKEN_URL\")\n",
    "tenantId=os.getenv(\"AZURE_TENANT_ID\")\n",
    "clientId=os.getenv(\"AZURE_CLIENT_ID\")\n",
    "clientSecret=os.getenv(\"AZURE_CLIENT_SECRET\")\n",
    "siteDomain = os.getenv(\"SITE_DOMAIN\")\n",
    "siteName = os.getenv(\"SITE_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to update the values for the cell below to match the characteristics of your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CODE CELL 11 ==========\n",
    "# Enable or disable display of variables\n",
    "displayVariables = True\n",
    "\n",
    "# Global variable definitions\n",
    "fileExtensions = [\"docx\",\"pdf\",\"pptx\"]\n",
    "sharepointPath=\"\"  # Empty string scans from root folder recursively\n",
    "filesystemPath = \"\"  # Empty string scans from root folder recursively (or specify path like r\"SampleFiles\")\n",
    "\n",
    "# Number of characters to be analyzed by Large Language Model (LLM) from each file\n",
    "# Increased from 800 to 2000 for better context and classification accuracy\n",
    "textLength=2000\n",
    "\n",
    "# Sample size for filesystem and SharePoint files\n",
    "sampleSize=0\n",
    "\n",
    "# Entity types for classification / assets\n",
    "entityTypes = [\n",
    "    'SharepointAccount',\n",
    "    'SharepointRootFolder',\n",
    "    'SharepointFolder',\n",
    "    'SharepointFile',\n",
    "    'FileSystemRoot',\n",
    "    'FileSystemFolder',\n",
    "    'FileSystemFile',\n",
    "    'DataSet'\n",
    "]\n",
    "\n",
    "# List of custom classifications to be created in Purview\n",
    "# This list can be customized based on the specific needs of the organization or project.\n",
    "classifications=[\n",
    "    \"Empty Content\", \n",
    "    \"Insurance Claim\",  \n",
    "    \"Sales Receipt\",  \n",
    "    \"Insurance Policy\",\n",
    "    \"Report\",\n",
    "    \"Invoice\",\n",
    "    \"PII\",\n",
    "    \"Other\"\n",
    "]\n",
    "# Convert classification list to string\n",
    "classificationsStr = ''.join(classification+'\\n' for classification in classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Configure Execution Parameters\n",
    "\n",
    "Set which sections of the notebook should execute. You can enable/disable specific demos and cleanup operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CODE CELL 13 ==========\n",
    "# ===== EXECUTION CONTROL PARAMETERS =====\n",
    "# Set these parameters to control which sections of the notebook execute\n",
    "# True = Execute the section, False = Skip the section\n",
    "\n",
    "# Execute SharePoint Demo (Section 2)\n",
    "RUN_SHAREPOINT_DEMO = True\n",
    "\n",
    "# Execute File System Demo (Section 3)\n",
    "RUN_FILESYSTEM_DEMO = True\n",
    "\n",
    "# Execute Cleanup (Section 4)\n",
    "RUN_CLEANUP = False\n",
    "\n",
    "print(\"Execution Configuration:\")\n",
    "print(f\"  SharePoint Demo: {'ENABLED' if RUN_SHAREPOINT_DEMO else 'DISABLED'}\")\n",
    "print(f\"  File System Demo: {'ENABLED' if RUN_FILESYSTEM_DEMO else 'DISABLED'}\")\n",
    "print(f\"  Cleanup: {'ENABLED' if RUN_CLEANUP else 'DISABLED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CODE CELL 14 ==========\n",
    "if displayVariables:\n",
    "    print(f\"Tenant ID: {tenantId}\")\n",
    "    print(f\"Client ID: {clientId}\") \n",
    "    print(f\"Azure OpenAI API Key: {azureOpenAIApiKey}\")\n",
    "    print(f\"Azure OpenAI Endpoint: {azureOpenAIApiEndpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CODE CELL 15 ==========\n",
    "if not tenantId or not clientId or not clientSecret or not azureOpenAIApiKey:\n",
    "    raise ValueError(\"Azure credentials are not set in the environment variables.\")\n",
    "\n",
    "# Generate token for REST API calls\n",
    "token = getAADToken(tenantId,clientId, clientSecret,purviewTokenUrl)\n",
    "\n",
    "# Authenticate with Microsoft Graph API\n",
    "response = sharepointClient.msgraph_auth()\n",
    "\n",
    "# Generate authentication credentials for Service Principal and Atlas client authentication for different Purview functions\n",
    "servicePrincipalAuth = ServicePrincipalAuthentication(\n",
    "    tenant_id=tenantId,\n",
    "    client_id=clientId,\n",
    "    client_secret=clientSecret\n",
    ")\n",
    "\n",
    "clientCredential = ClientSecretCredential(\n",
    "    tenant_id=tenantId,\n",
    "    client_id=clientId,\n",
    "    client_secret=clientSecret\n",
    ")\n",
    "\n",
    "# Create clients for Purview administration and Azure AI Foundry\n",
    "purviewClient = PurviewClient(\n",
    "    account_name = purviewAccountName,\n",
    "    authentication = clientCredential\n",
    ")\n",
    "\n",
    "collectionClient = PurviewCollections(\n",
    "    purview_account_name=purviewAccountName,\n",
    "    auth = servicePrincipalAuth\n",
    ")\n",
    "\n",
    "llmClient = ChatCompletionsClient(\n",
    "    endpoint=azureOpenAIApiEndpoint,\n",
    "    credential=AzureKeyCredential(azureOpenAIApiKey),\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Create Purview asset dependencies\n",
    "\n",
    "Creates entity type definitions and classifications required by the Purview clients to assign classifications to assets discovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CODE CELL 17 - RELATIONSHIP TYPE DEFINITIONS ==========\n",
    "# Creation of custom Entity Types with hierarchical relationship attributes\n",
    "# The list of Entity Types is taken from the variable named entityTypes\n",
    "from pyapacheatlas.core.typedef import AtlasAttributeDef, RelationshipTypeDef, AtlasRelationshipEndDef, Cardinality\n",
    "\n",
    "# Step 1: Create Entity Type definitions FIRST (relationships need these to exist)\n",
    "print(\"Creating entity type definitions...\")\n",
    "for entityName in entityTypes:\n",
    "    if entityName == \"DataSet\":\n",
    "        # Built-in type; do not attempt to upload/modify\n",
    "        continue\n",
    "    \n",
    "    edef = EntityTypeDef(\n",
    "        name=entityName,\n",
    "        superTypes=['DataSet']\n",
    "    )\n",
    "    results = purviewClient.upload_typedefs(\n",
    "        entityDefs=[edef],\n",
    "        force_update=True,\n",
    "    )\n",
    "    print(f\"‚úÖ Created entity type: {entityName}\")\n",
    "\n",
    "# Step 2: Create RelationshipTypeDef objects (now that entity types exist)\n",
    "print(\"\\nCreating relationship type definitions...\")\n",
    "\n",
    "# SharePoint relationship types\n",
    "sharepoint_relationships = [\n",
    "    RelationshipTypeDef(\n",
    "        name='sharepoint_account_root',\n",
    "        relationshipCategory='COMPOSITION',\n",
    "        endDef1=AtlasRelationshipEndDef(typeName='SharepointAccount', name='rootFolders', isContainer=True, cardinality=Cardinality.SET),\n",
    "        endDef2=AtlasRelationshipEndDef(typeName='SharepointRootFolder', name='account', isContainer=False, cardinality=Cardinality.SINGLE)\n",
    "    ),\n",
    "    RelationshipTypeDef(\n",
    "        name='sharepoint_root_folder',\n",
    "        relationshipCategory='COMPOSITION',\n",
    "        endDef1=AtlasRelationshipEndDef(typeName='SharepointRootFolder', name='folders', isContainer=True, cardinality=Cardinality.SET),\n",
    "        endDef2=AtlasRelationshipEndDef(typeName='SharepointFolder', name='rootFolder', isContainer=False, cardinality=Cardinality.SINGLE)\n",
    "    ),\n",
    "    RelationshipTypeDef(\n",
    "        name='sharepoint_folder_subfolder',\n",
    "        relationshipCategory='COMPOSITION',\n",
    "        endDef1=AtlasRelationshipEndDef(typeName='SharepointFolder', name='subfolders', isContainer=True, cardinality=Cardinality.SET),\n",
    "        endDef2=AtlasRelationshipEndDef(typeName='SharepointFolder', name='parentFolder', isContainer=False, cardinality=Cardinality.SINGLE)\n",
    "    ),\n",
    "    RelationshipTypeDef(\n",
    "        name='sharepoint_folder_files',\n",
    "        relationshipCategory='COMPOSITION',\n",
    "        endDef1=AtlasRelationshipEndDef(typeName='SharepointFolder', name='files', isContainer=True, cardinality=Cardinality.SET),\n",
    "        endDef2=AtlasRelationshipEndDef(typeName='SharepointFile', name='folder', isContainer=False, cardinality=Cardinality.SINGLE)\n",
    "    ),\n",
    "    RelationshipTypeDef(\n",
    "        name='sharepoint_root_files',\n",
    "        relationshipCategory='COMPOSITION',\n",
    "        endDef1=AtlasRelationshipEndDef(typeName='SharepointRootFolder', name='files', isContainer=True, cardinality=Cardinality.SET),\n",
    "        endDef2=AtlasRelationshipEndDef(typeName='SharepointFile', name='rootFolder', isContainer=False, cardinality=Cardinality.SINGLE)\n",
    "    )\n",
    "]\n",
    "\n",
    "# FileSystem relationship types\n",
    "filesystem_relationships = [\n",
    "    RelationshipTypeDef(\n",
    "        name='filesystem_root_folder',\n",
    "        relationshipCategory='COMPOSITION',\n",
    "        endDef1=AtlasRelationshipEndDef(typeName='FileSystemRoot', name='folders', isContainer=True, cardinality=Cardinality.SET),\n",
    "        endDef2=AtlasRelationshipEndDef(typeName='FileSystemFolder', name='root', isContainer=False, cardinality=Cardinality.SINGLE)\n",
    "    ),\n",
    "    RelationshipTypeDef(\n",
    "        name='filesystem_folder_subfolder',\n",
    "        relationshipCategory='COMPOSITION',\n",
    "        endDef1=AtlasRelationshipEndDef(typeName='FileSystemFolder', name='subfolders', isContainer=True, cardinality=Cardinality.SET),\n",
    "        endDef2=AtlasRelationshipEndDef(typeName='FileSystemFolder', name='parentFolder', isContainer=False, cardinality=Cardinality.SINGLE)\n",
    "    ),\n",
    "    RelationshipTypeDef(\n",
    "        name='filesystem_folder_files',\n",
    "        relationshipCategory='COMPOSITION',\n",
    "        endDef1=AtlasRelationshipEndDef(typeName='FileSystemFolder', name='files', isContainer=True, cardinality=Cardinality.SET),\n",
    "        endDef2=AtlasRelationshipEndDef(typeName='FileSystemFile', name='folder', isContainer=False, cardinality=Cardinality.SINGLE)\n",
    "    ),\n",
    "    RelationshipTypeDef(\n",
    "        name='filesystem_root_files',\n",
    "        relationshipCategory='COMPOSITION',\n",
    "        endDef1=AtlasRelationshipEndDef(typeName='FileSystemRoot', name='files', isContainer=True, cardinality=Cardinality.SET),\n",
    "        endDef2=AtlasRelationshipEndDef(typeName='FileSystemFile', name='root', isContainer=False, cardinality=Cardinality.SINGLE)\n",
    "    )\n",
    "]\n",
    "\n",
    "# Upload relationship type definitions\n",
    "all_relationships = sharepoint_relationships + filesystem_relationships\n",
    "results = purviewClient.upload_typedefs(\n",
    "    relationshipDefs=all_relationships,\n",
    "    force_update=True\n",
    ")\n",
    "print(f\"‚úÖ Created {len(all_relationships)} relationship type definitions\")\n",
    "\n",
    "# Step 3: Creation of custom Classifications\n",
    "# The list of classifications is taken from the variable named classifications\n",
    "for classification in classifications:\n",
    "    # Create custom classifications to be applied to unstructured data assets\n",
    "    cdef = ClassificationTypeDef(\n",
    "        name=classification,\n",
    "        # entityTypes will restrict the types of assets that can be associated with this classification.\n",
    "        entityTypes=entityTypes\n",
    "    )\n",
    "    # Do the upload\n",
    "    results = purviewClient.upload_typedefs(\n",
    "        classificationDefs=[cdef],\n",
    "        force_update=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Create custom collections\n",
    "\n",
    "Creates multiple custom collection under the parent Start_Collection (Domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create multiple collections, the parent collection defined by the start_collection parameter\n",
    "# MUST exist.\n",
    "response = collectionClient.create_collections(start_collection=purviewAccountName,\n",
    "                          collection_names=['Unstructured/SharePoint','Unstructured/FileSystem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Capture Sampling Size\n",
    "\n",
    "This will help to determine the number of files that will be analyzed for classification purposes.\n",
    "\n",
    "> üìå **Note:**\n",
    "> Currently is a fixed size, but it could be changed to represent a percentage of the total number of files found during the scan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampleSize = input(f\"Enter how many documents to analyze: \")\n",
    "if sampleSize.isnumeric():\n",
    "    sampleSize = int(sampleSize)\n",
    "else:\n",
    "    sampleSize = 0\n",
    "print(f\"\\n{sampleSize} documents will be analyzed from the list of documents found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SharePoint Demo\n",
    "\n",
    "‚öôÔ∏è **Controlled by parameter:** `RUN_SHAREPOINT_DEMO`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Scan SharePoint Site\n",
    "\n",
    "üí° Skip this cell if `RUN_SHAREPOINT_DEMO = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO:\n",
    "    \"\"\"\n",
    "    List all the files in SharePoint site that match the defined file extensions. \n",
    "    \"\"\"\n",
    "    spFileList = sharepointClient.listSharepointFiles(\n",
    "        site_domain=siteDomain,\n",
    "        site_name=siteName,\n",
    "        file_formats = fileExtensions,\n",
    "        folder_path=sharepointPath if sharepointPath else None,\n",
    "        # Files modified N minutes ago\n",
    "        # minutes_ago=60,\n",
    "    )\n",
    "    \n",
    "    # Handle None return (API error or no files found)\n",
    "    if spFileList is None:\n",
    "        print(\"‚ö†Ô∏è  No files found or SharePoint API error occurred\")\n",
    "        spFileList = []\n",
    "    else:\n",
    "        print(f\"{len(spFileList)} files found matching the patterns {fileExtensions}: \\n\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping SharePoint Demo - RUN_SHAREPOINT_DEMO is False\")\n",
    "    spFileList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO and displayVariables == True:\n",
    "    print(json.dumps(spFileList, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generate file subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO:\n",
    "    # Create a subset of the spFileList based on the number specified by sampleSize. If no subset is provided, the entire list will be used.\n",
    "    if sampleSize == 0 or sampleSize > len(spFileList):\n",
    "            sampleSize = len(spFileList)\n",
    "    # Create a subset of the SharePoint file list\n",
    "    spFileSubset = sharepointClient.sharepointFileSampleList(spFileList,sampleSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO and displayVariables:\n",
    "    print(f\"\\nSubset of SharePoint files to be analyzed: {sampleSize} files\\n\")\n",
    "    for file in spFileSubset:\n",
    "        print(f\"{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Extract file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO:\n",
    "    \"\"\"\n",
    "    Extract file contents and process all file information included in the subset from a \n",
    "    specific Site ID.\n",
    "    \"\"\"\n",
    "    spFileContent = sharepointClient.getSharepointFileContent(\n",
    "        site_domain=os.environ[\"SITE_DOMAIN\"],\n",
    "        site_name=os.environ[\"SITE_NAME\"],\n",
    "        folder_path=sharepointPath,\n",
    "        file_names=spFileSubset\n",
    "        # Files modified N minutes ago\n",
    "        # minutes_ago=60,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO and displayVariables:\n",
    "    print(json.dumps(spFileContent, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Analyze File Contents with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the number of tokens that will be used by LLM model, prior to processing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO:\n",
    "    tokens = estimateTokens(spFileContent,textLength,classificationsStr,azureOpenAILLMModel)\n",
    "    print(f\"Estimated Number of Tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Classify document contents using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO:\n",
    "    \"\"\"\n",
    "    Analyze SharePoint folder contents using Large Language Model to determine applicable\n",
    "    classifications. \n",
    "    \"\"\"\n",
    "    spFileContent = unstructuredDataClassification(spFileContent,textLength,llmClient,azureOpenAIDeploymentName,classificationsStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Organize and Rollup Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO:\n",
    "    \"\"\"\n",
    "    Collect document classifications identified for SharePoint folder\n",
    "    \"\"\"\n",
    "    spClassifications = rollupClassifications(spFileContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO and displayVariables:\n",
    "    print(f\"\\nClassifications for SharePoint files: {spClassifications}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Ingest assets into Purview via Atlas API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO:\n",
    "    \"\"\"\n",
    "    Load SharePoint Assets in Purview.\n",
    "    \"\"\"\n",
    "    spGuids = loadPurviewAssets(purviewClient,spFileContent)\n",
    "else:\n",
    "    spGuids = {\"all\": [], \"file\": []}\n",
    "# Normalize legacy list return shape\n",
    "if isinstance(spGuids, list):\n",
    "    spGuids = {\"all\": spGuids, \"file\": spGuids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO and displayVariables:\n",
    "    print(f\"SharePoint GUIDs (all): {spGuids.get('all', [])}\")\n",
    "    print(f\"SharePoint File GUIDs: {spGuids.get('file', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Apply classifications to assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO:\n",
    "    \"\"\"\n",
    "    Apply classification to SharePoint assets\n",
    "    \"\"\"\n",
    "    result = applyPurviewClassifications(purviewClient,spGuids.get('file', []),spClassifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Move assets to their final collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SHAREPOINT_DEMO:\n",
    "    \"\"\"\n",
    "    Move assets from default (root) collection to collectionName\n",
    "    \"\"\"\n",
    "    collectionName = 'SharePoint'\n",
    "    output = moveCollection(collectionName,purviewEndpointUrl,token,spGuids.get('all', []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. File System Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Scan Filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_FILESYSTEM_DEMO:\n",
    "    \"\"\"\n",
    "    List all the files in Filesystem that match the defined file extensions. \n",
    "    \"\"\"\n",
    "    fsFileList = listFilesystemFiles(filesystemPath, fileExtensions)\n",
    "    print(f\"{len(fsFileList)} files found matching the patterns {fileExtensions}\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping FileSystem Demo - RUN_FILESYSTEM_DEMO is False\")\n",
    "    fsFileList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_FILESYSTEM_DEMO and displayVariables:\n",
    "    for file in fsFileList:\n",
    "        print(f\"{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Generate file subset and extract contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_FILESYSTEM_DEMO:\n",
    "    \"\"\"\n",
    "    Create a subset of the fsFileList based on the number specified by sampleSize, extract file \n",
    "    contents, and metadata.\n",
    "    \"\"\"\n",
    "    if sampleSize == 0 or sampleSize > len(fsFileList):\n",
    "            sampleSize = len(fsFileList)\n",
    "\n",
    "    fsFileContent = filesystemFileSampleList(fsFileList,sampleSize,filesystemPath)\n",
    "else:\n",
    "    fsFileContent = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_FILESYSTEM_DEMO and displayVariables:\n",
    "    fsFileContent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Estimate number of tokens to be used by LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_FILESYSTEM_DEMO:\n",
    "    tokens = estimateTokens(fsFileContent,textLength,classificationsStr,azureOpenAILLMModel)\n",
    "    print(f\"Estimated Number of Tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Classify document contents using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_FILESYSTEM_DEMO:\n",
    "    \"\"\"\n",
    "    Analyze Filesystem folder contents using Large Language Model to determine applicable\n",
    "    classifications. \n",
    "    \"\"\"\n",
    "    fsFileContent = unstructuredDataClassification(fsFileContent,textLength,llmClient,azureOpenAIDeploymentName,classificationsStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Organize and Rollup Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_FILESYSTEM_DEMO:\n",
    "    \"\"\"\n",
    "    Collect document classifications identified for FileSystem folder\n",
    "    \"\"\"\n",
    "    fsClassifications = rollupClassifications(fsFileContent)\n",
    "else:\n",
    "    fsClassifications = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_FILESYSTEM_DEMO and displayVariables:\n",
    "    print(f\"\\nClassifications for FileSystem files: {fsClassifications}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Ingest assets into Purview via Atlas API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_FILESYSTEM_DEMO:\n",
    "    \"\"\"\n",
    "    Load FileSystem Assets in Purview.\n",
    "    \"\"\"\n",
    "    fsGuids = loadPurviewAssets(purviewClient,fsFileContent)\n",
    "    # Normalize to dict format if loadPurviewAssets returned a list (backward compatibility)\n",
    "    if isinstance(fsGuids, list):\n",
    "        fsGuids = {\"all\": fsGuids, \"file\": fsGuids}\n",
    "else:\n",
    "    fsGuids = {\"all\": [], \"file\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_FILESYSTEM_DEMO and displayVariables:\n",
    "    print(f\"\\nFileSystem GUIDs (all): {fsGuids.get('all', [])}\")\n",
    "    print(f\"FileSystem File GUIDs: {fsGuids.get('file', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Apply classifications to assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_FILESYSTEM_DEMO:\n",
    "    \"\"\"\n",
    "    Apply classification to FileSystem assets\n",
    "    \"\"\"\n",
    "    result = applyPurviewClassifications(purviewClient,fsGuids.get('file', []),fsClassifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Move assets to their final collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_FILESYSTEM_DEMO:\n",
    "    \"\"\"\n",
    "    Move collections from default (root) collection to collectionName\n",
    "    \"\"\"\n",
    "    collectionName = 'FileSystem'\n",
    "    output = moveCollection(collectionName,purviewEndpointUrl,token,fsGuids.get('all', []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cleanup section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"‚è≥ Waiting before cleanup...\")\n",
    "print(\"This pause allows you to review the assets in Purview before they are deleted.\")\n",
    "print(\"Press Ctrl+C to cancel cleanup, or wait for the countdown to complete.\\n\")\n",
    "\n",
    "wait_time = 300  # seconds\n",
    "\n",
    "try:\n",
    "    for remaining in range(wait_time, 0, -1):\n",
    "        print(f\"Cleanup will begin in {remaining} seconds...\", end='\\r')\n",
    "        time.sleep(1)\n",
    "    print(\"\\n‚úÖ Proceeding with cleanup...\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n‚ö†Ô∏è Cleanup cancelled by user.\")\n",
    "    RUN_CLEANUP = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Delete assets and collections\n",
    "\n",
    "You can delete individual assets using their respective GUIDs or you can leverage the collectionClient to delete collections recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CLEANUP:\n",
    "    print(\"üóëÔ∏è  Step 1: Querying and deleting all custom type assets...\")\n",
    "    # Query for all entities of custom types and delete them\n",
    "    deleted_count = 0\n",
    "    \n",
    "    # First delete from session GUIDs if available\n",
    "    session_guids = [*spGuids.get('all', []), *fsGuids.get('all', [])]\n",
    "    for guid in session_guids:\n",
    "        try:\n",
    "            response = purviewClient.delete_entity(guid=guid)\n",
    "            deleted_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Could not delete {guid}: {e}\")\n",
    "    \n",
    "    # Query and delete any remaining entities of custom types\n",
    "    for entityType in ['SharepointAccount', 'SharepointRootFolder', 'SharepointFolder', 'SharepointFile', \n",
    "                       'FileSystemRoot', 'FileSystemFolder', 'FileSystemFile']:\n",
    "        try:\n",
    "            search_results = purviewClient.search_entities(f\"typeName:{entityType}\")\n",
    "            if search_results and 'value' in search_results:\n",
    "                for entity in search_results['value']:\n",
    "                    try:\n",
    "                        purviewClient.delete_entity(guid=entity['id'])\n",
    "                        deleted_count += 1\n",
    "                        print(f\"  üóëÔ∏è  Deleted {entityType}: {entity.get('name', entity['id'])}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  ‚ö†Ô∏è  Could not delete {entity['id']}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Could not query {entityType}: {e}\")\n",
    "    \n",
    "    print(f\"  ‚úÖ Deleted {deleted_count} assets\")\n",
    "    \n",
    "    print(\"\\nüóëÔ∏è  Step 2: Deleting collections...\")\n",
    "    try:\n",
    "        collectionClient.delete_collections_recursively(\"Unstructured\", delete_assets=True)\n",
    "        collectionClient.delete_collections(\"Unstructured\")\n",
    "        print(\"  ‚úÖ Collections deleted\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Could not delete collections: {e}\")\n",
    "    \n",
    "    import time\n",
    "    print(\"\\n‚è≥ Waiting 15 seconds for asset deletion to propagate...\")\n",
    "    time.sleep(15)\n",
    "    \n",
    "    print(\"\\nüóëÔ∏è  Step 3: Deleting relationship type definitions...\")\n",
    "    relationship_types = [\n",
    "        'sharepoint_account_root', 'sharepoint_root_folder', 'sharepoint_folder_subfolder',\n",
    "        'sharepoint_folder_files', 'sharepoint_root_files',\n",
    "        'filesystem_root_folder', 'filesystem_folder_subfolder', \n",
    "        'filesystem_folder_files', 'filesystem_root_files'\n",
    "    ]\n",
    "    for rel_type in relationship_types:\n",
    "        try:\n",
    "            purviewClient.delete_type(rel_type)\n",
    "            print(f\"  ‚úÖ Deleted relationship type: {rel_type}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Could not delete {rel_type}: {e}\")\n",
    "    \n",
    "    print(\"\\nüóëÔ∏è  Step 4: Deleting custom classifications...\")\n",
    "    for classification in classifications:\n",
    "        try:\n",
    "            purviewClient.delete_type(classification)\n",
    "            print(f\"  ‚úÖ Deleted classification: {classification}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Could not delete {classification}: {e}\")\n",
    "\n",
    "    print(\"\\nüóëÔ∏è  Step 5: Deleting custom entity types...\")\n",
    "    for entityName in entityTypes:\n",
    "        if entityName == \"DataSet\":\n",
    "            continue\n",
    "        try:\n",
    "            edef = EntityTypeDef(\n",
    "                name = entityName,\n",
    "                superTypes= ['DataSet']\n",
    "            )\n",
    "            results = purviewClient.delete_typedefs(\n",
    "                entityDefs=[edef],\n",
    "                force_update=True\n",
    "            )\n",
    "            print(f\"  ‚úÖ Deleted entity type: {entityName}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Could not delete {entityName}: {e}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Cleanup complete!\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping Cleanup - RUN_CLEANUP is False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CLEANUP:\n",
    "    # Delete all Jupyter notebook variables\n",
    "    %reset -f\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping variable reset - RUN_CLEANUP is False\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
